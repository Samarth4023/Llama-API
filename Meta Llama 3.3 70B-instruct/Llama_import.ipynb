{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c34b43-49ae-42e0-a185-80aaa19b9ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1097671</td>\n",
       "      <td>Compare and contrast the importance of self-reliance and adaptability in healthcare.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1726150</td>\n",
       "      <td>Evaluate the effectiveness of management consulting in addressing conflicts within marketing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3211968</td>\n",
       "      <td>Discuss the role of self-reliance in achieving success in software engineering.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "0  1097671   \n",
       "1  1726150   \n",
       "2  3211968   \n",
       "\n",
       "                                                                                           topic  \n",
       "0           Compare and contrast the importance of self-reliance and adaptability in healthcare.  \n",
       "1  Evaluate the effectiveness of management consulting in addressing conflicts within marketing.  \n",
       "2                Discuss the role of self-reliance in achieving success in software engineering.  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.display import display\n",
    "from accelerate import infer_auto_device_map, dispatch_model\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, AutoModel, LlamaTokenizer\n",
    "\n",
    "if (not torch.cuda.is_available()): print(\"Sorry - GPU required!\")\n",
    "    \n",
    "import logging\n",
    "logging.getLogger('transformers').setLevel(logging.ERROR)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a200e5b-fe98-4183-b0bf-c79f7567691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU memory and delete existing objects if they exist\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "for obj in ['model', 'pipe', 'tokenizer']:\n",
    "    if obj in globals():\n",
    "        del globals()[obj]\n",
    "\n",
    "# Model configuration\n",
    "model_name = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load model configuration (you need this for custom `device_map`)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,  # Use bfloat16 to save memory\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# Infer device map (set layers to offload to disk if they don't fit in memory)\n",
    "device_map = infer_auto_device_map(\n",
    "    model,\n",
    "    max_memory={\"cuda\": \"3GiB\", \"cpu\": \"2.0GiB\"},  # Adjust according to your hardware\n",
    "    no_split_module_classes=[\"LlamaDecoderLayer\"],  # Update if using a different model\n",
    ")\n",
    "\n",
    "# Dispatch the model with disk_offload\n",
    "dispatch_model(\n",
    "    model,\n",
    "    device_map=device_map,\n",
    "    offload_dir=\"offload\",  # Directory for offloaded layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dff1ab-9a0e-45af-be93-a5e7d2075b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vanquisher",
   "language": "python",
   "name": "vanquisher"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
